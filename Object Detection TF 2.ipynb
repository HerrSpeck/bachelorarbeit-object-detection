{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43d77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and libs\n",
    "import os\n",
    "import os.path\n",
    "import pathlib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import time\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7548f22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a821c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all models endorsed by the official tf object detection tutorial that were trained on the COCO 2017 training set\n",
    "ALL_MODELS = {\n",
    "    'EfficientDet D7 1536x1536' : 'https://tfhub.dev/tensorflow/efficientdet/d7/1',\n",
    "    'SSD ResNet152 V1 FPN 1024x1024' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_1024x1024/1',\n",
    "    'Faster R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e83fdbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d089d422fb734e79b0bfc0c52e3c920a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loaded: ', max=99), Label(value='0 / 99')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load images from inputs folder\n",
    "IMAGES = []\n",
    "VALID_PATHS = []\n",
    "running = []\n",
    "\n",
    "# Get all valid image paths\n",
    "file_path = 'inputs/colorized_stable/' # use colorized_artistic for artistic model\n",
    "for image_path in os.listdir(file_path):\n",
    "    if (image_path.endswith('.jpg')):\n",
    "        # Collect image as valid path\n",
    "        VALID_PATHS.append(image_path)\n",
    "        \n",
    "progress_load = widgets.IntProgress(min=0, max=len(VALID_PATHS), description='Loaded: ') # instantiate the bar\n",
    "load_label = widgets.Label(value='0 / ' + str(len(VALID_PATHS)))\n",
    "display(widgets.HBox([progress_load, load_label])) # display the bar\n",
    "\n",
    "# Load given image into numpy array using matplotlib imload\n",
    "def load_valid_image(path):\n",
    "    img = mpimg.imread(file_path + path, format='jpg')\n",
    "    # Reshape image array to fit specifications required by tensorflow model\n",
    "    (rows, columns, channels) = img.shape\n",
    "    IMAGES.append({\n",
    "        'image': img.reshape((1, rows, columns, channels)),\n",
    "        'filename': path,\n",
    "        'detection': {}\n",
    "    })\n",
    "    progress_load.value += 1\n",
    "    load_label.value = str(progress_load.value) + ' / ' + str(len(VALID_PATHS))\n",
    "\n",
    "# Parallelize execution with threadpool\n",
    "def run_with_Threadpool(paths):\n",
    "    with ThreadPoolExecutor(max_workers=(os.cpu_count() * 5)) as executor:\n",
    "        # Schedule task for each image\n",
    "        running = [executor.submit(\n",
    "            lambda: load_valid_image(path)\n",
    "        ) for path in paths]\n",
    "\n",
    "\"\"\"\n",
    "    Since we are working with a lot of IO operations, we use Threadpool since it is much faster for IO than using Processes:\n",
    "    \n",
    "    Loading 20 images:\n",
    "        Runtime with Processes: ~20 seconds\n",
    "        Runtime with Threadpool: ~3 seconds\n",
    "\"\"\"\n",
    "# Load all valid images\n",
    "# start_time = time.time()\n",
    "# run_with_Threadpool(VALID_PATHS)\n",
    "# print(\"--- Runtime with Threadpool: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "for path in VALID_PATHS:\n",
    "    load_valid_image(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ec51d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c556c193064ae5b01765a8038b3b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=99), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw first image\n",
    "@widgets.interact(i=(0, len(IMAGES)))\n",
    "def show_image_at(i=0):\n",
    "    plt.figure(figsize=(18,26))\n",
    "    plt.imshow(IMAGES[i]['image'][0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "816f1ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load object detection lib\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Path to predefined labels for the coco 2017 training set\n",
    "PATH_TO_LABELS = './tensorflow_models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "595d60be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model: EfficientDet D7 1536x1536\n",
      "Model Handle at TensorFlow Hub: https://tfhub.dev/tensorflow/efficientdet/d7/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_EfficientDet-D6-D7_layer_call_and_return_conditional_losses_233604) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_169633) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___54382) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D6-D7_layer_call_and_return_conditional_losses_218766) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D6-D7_layer_call_and_return_conditional_losses_209972) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_166209) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D6-D7_layer_call_and_return_conditional_losses_242398) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "# Select model\n",
    "model_display_name = 'EfficientDet D7 1536x1536'\n",
    "model_handle = ALL_MODELS[model_display_name]\n",
    "\n",
    "print('Selected model: '+ model_display_name)\n",
    "print('Model Handle at TensorFlow Hub: {}'.format(model_handle))\n",
    "\n",
    "# Load model\n",
    "hub_model = hub.load(model_handle)\n",
    "print('Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d2bfed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7860dcf9fc49e8bbc78b64fbb73cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Inferred: ', max=99), Label(value='0 / 99')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Runtime: 2.96 minutes ---\n"
     ]
    }
   ],
   "source": [
    "# running inference\n",
    "# different object detection models have additional results\n",
    "# all of them are explained in the documentation\n",
    "progress_inference = widgets.IntProgress(min=0, max=len(IMAGES), description='Inferred: ')\n",
    "inference_label = widgets.Label(value='0 / ' + str(len(IMAGES)))\n",
    "display(widgets.HBox([progress_inference, inference_label]))\n",
    "\n",
    "start_time = time.time()\n",
    "for image in IMAGES:\n",
    "    # Run object detection and save results\n",
    "    detected = hub_model(image['image'])\n",
    "    image['detection'] = {key:value.numpy() for key,value in detected.items()}\n",
    "    \n",
    "    progress_inference.value += 1\n",
    "    inference_label.value = str(progress_inference.value) + ' / ' + str(len(IMAGES))\n",
    "    \n",
    "runtime = ((time.time() - start_time) / 60)\n",
    "print(\"--- Runtime: \" + f'{runtime:.2f}' + \" minutes ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b438766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy image to draw detected objects\n",
    "IMAGES_WITH_DETECTION = []\n",
    "for image in IMAGES:\n",
    "    IMAGES_WITH_DETECTION.append({\n",
    "        'image': image['image'].copy(),\n",
    "        'filename': image['filename'],\n",
    "        'detection': image['detection']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0afc043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c993b32d798b4d098c65c2b7bbf98318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=99), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw detections on copied image\n",
    "for image in IMAGES_WITH_DETECTION:\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image['image'][0],\n",
    "          image['detection']['detection_boxes'][0],\n",
    "          (image['detection']['detection_classes'][0]).astype(int),\n",
    "          image['detection']['detection_scores'][0],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          # Change this if confidence score should be higher or lower\n",
    "          min_score_thresh=.50,\n",
    "          line_thickness=6,\n",
    "          agnostic_mode=False\n",
    "    )\n",
    "\n",
    "# Draw first new image\n",
    "@widgets.interact(i=(0, len(IMAGES_WITH_DETECTION)))\n",
    "def show_image_at(i=0):\n",
    "    plt.figure(figsize=(24,32))\n",
    "    plt.imshow(IMAGES_WITH_DETECTION[i]['image'][0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf0cc8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08c2173e1f04ad687271b0be50f4219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Saved: ', max=99), Label(value='0 / 99')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add output sub-directory named after the model that was used (if it doesn't already exist)\n",
    "output_dir = 'outputs/' + model_display_name + '/'\n",
    "pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "progress_save = widgets.IntProgress(min=0, max=len(IMAGES_WITH_DETECTION), description='Saved: ')\n",
    "save_label = widgets.Label(value='0 / ' + str(len(IMAGES_WITH_DETECTION)))\n",
    "display(widgets.HBox([progress_save, save_label]))\n",
    "\n",
    "# Save images\n",
    "for image in IMAGES_WITH_DETECTION:\n",
    "    plt.imsave(output_dir + image['filename'], image['image'][0], format='jpg')\n",
    "    \n",
    "    progress_save.value += 1\n",
    "    save_label.value = str(progress_save.value) + ' / ' + str(len(IMAGES_WITH_DETECTION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76535c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
