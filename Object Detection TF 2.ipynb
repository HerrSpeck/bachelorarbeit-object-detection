{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43d77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and libs\n",
    "import os\n",
    "import os.path\n",
    "import pathlib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import PIL.Image as Image\n",
    "import PIL.ImageColor as ImageColor\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import PIL.ImageFont as ImageFont\n",
    "\n",
    "import six\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import collections\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import time\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7548f22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a821c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all models endorsed by the official tf object detection tutorial that were trained on the COCO 2017 training set\n",
    "ALL_MODELS = {\n",
    "    'EfficientDet' : 'https://tfhub.dev/tensorflow/efficientdet/d7/1',\n",
    "    'Faster R-CNN' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1',\n",
    "    'Faster R-CNN (OpenImages)' : 'https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1',\n",
    "    'CenterNet' : 'https://tfhub.dev/tensorflow/centernet/resnet101v1_fpn_512x512/1'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "816f1ff9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'object_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e0c7a342f2cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load object detection lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mviz_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mutils_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'"
     ]
    }
   ],
   "source": [
    "# Load object detection lib\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Path to predefined labels for the openimages v4 training set\n",
    "PATH_TO_LABELS = './tensorflow_models/research/object_detection/data/oid_v4_label_map.pbtxt'\n",
    "# Path to predefined labels for the coco 2017 training set\n",
    "# PATH_TO_LABELS = './tensorflow_models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595d60be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select model\n",
    "model_display_name = 'EfficientDet'\n",
    "model_handle = ALL_MODELS[model_display_name]\n",
    "\n",
    "print('Selected model: '+ model_display_name)\n",
    "print('Model Handle at TensorFlow Hub: {}'.format(model_handle))\n",
    "\n",
    "# Load model\n",
    "hub_model = hub.load(model_handle)\n",
    "print('Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef06051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from inputs folder\n",
    "IMAGES = []\n",
    "VALID_PATHS = []\n",
    "running = []\n",
    "\n",
    "# Get all valid image paths\n",
    "# image_type = 'colorized_artistic' # use this for brighter/more daring colors\n",
    "# image_type = 'grayscale' # use this for the original grayscale images\n",
    "image_type = 'colorized_stable' # use this for most stable results\n",
    "file_path = 'inputs/' + image_type + '/'\n",
    "for image_path in os.listdir(file_path):\n",
    "    if (image_path.endswith('.jpg')):\n",
    "        # Collect image as valid path\n",
    "        VALID_PATHS.append(image_path)\n",
    "        \n",
    "progress_load = widgets.IntProgress(min=0, max=len(VALID_PATHS), description='Loaded: ') # instantiate the bar\n",
    "load_label = widgets.Label(value='0 / ' + str(len(VALID_PATHS)))\n",
    "display(widgets.HBox([progress_load, load_label])) # display the bar\n",
    "\n",
    "# Load given image into numpy array using matplotlib imload\n",
    "def load_valid_image(path):\n",
    "    img = mpimg.imread(file_path + path, format='jpg')\n",
    "    # Reshape image array to fit specifications required by tensorflow model\n",
    "    (rows, columns, channels) = img.shape\n",
    "    IMAGES.append({\n",
    "        'image': img.reshape((1, rows, columns, channels)),\n",
    "        'filename': path,\n",
    "        'detection': {}\n",
    "    })\n",
    "    progress_load.value += 1\n",
    "    load_label.value = str(progress_load.value) + ' / ' + str(len(VALID_PATHS))\n",
    "\n",
    "# Parallelize execution with threadpool\n",
    "def run_with_Threadpool(paths):\n",
    "    with ThreadPoolExecutor(max_workers=(os.cpu_count() * 5)) as executor:\n",
    "        # Schedule task for each image\n",
    "        running = [executor.submit(\n",
    "            lambda: load_valid_image(path)\n",
    "        ) for path in paths]\n",
    "\n",
    "\"\"\"\n",
    "    Since we are working with a lot of IO operations, we use Threadpool since it is much faster for IO than using Processes:\n",
    "    \n",
    "    Loading 20 images:\n",
    "        Runtime with Processes: ~20 seconds\n",
    "        Runtime with Threadpool: ~3 seconds\n",
    "\"\"\"\n",
    "# Load all valid images\n",
    "# start_time = time.time()\n",
    "# run_with_Threadpool(VALID_PATHS)\n",
    "# print(\"--- Runtime with Threadpool: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "for path in VALID_PATHS:\n",
    "    load_valid_image(path)\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f0256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw first image\n",
    "@widgets.interact(i=(0, len(IMAGES)))\n",
    "def show_image_at(i=0):\n",
    "    plt.figure(figsize=(18,26))\n",
    "    plt.imshow(IMAGES[i]['image'][0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2bfed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running inference\n",
    "# different object detection models have additional results\n",
    "# all of them are explained in the documentation\n",
    "progress_inference = widgets.IntProgress(min=0, max=len(IMAGES), description='Inferred: ')\n",
    "inference_label = widgets.Label(value='0 / ' + str(len(IMAGES)))\n",
    "display(widgets.HBox([progress_inference, inference_label]))\n",
    "\n",
    "start_time = time.time()\n",
    "for image in IMAGES:\n",
    "    # Run object detection and save results\n",
    "    detected = hub_model(image['image'])\n",
    "    image['detection'] = {key:value.numpy() for key,value in detected.items()}\n",
    "    \n",
    "    progress_inference.value += 1\n",
    "    inference_label.value = str(progress_inference.value) + ' / ' + str(len(IMAGES))\n",
    "    \n",
    "runtime = ((time.time() - start_time) / 60)\n",
    "print(\"--- Runtime: \" + f'{runtime:.2f}' + \" minutes ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b438766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy image to draw detected objects\n",
    "IMAGES_WITH_DETECTION = []\n",
    "for image in IMAGES:\n",
    "    IMAGES_WITH_DETECTION.append({\n",
    "        'image': image['image'].copy(),\n",
    "        'filename': image['filename'],\n",
    "        'detection': image['detection']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32e7852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use shortened version of function from tensorflow library, to add font-size support\n",
    "STANDARD_COLORS = [\n",
    "    'AliceBlue', 'Chartreuse', 'Aqua', 'Aquamarine', 'Azure', 'Beige', 'Bisque',\n",
    "    'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue', 'AntiqueWhite',\n",
    "    'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson', 'Cyan',\n",
    "    'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n",
    "    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet',\n",
    "    'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n",
    "    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'Gold', 'GoldenRod',\n",
    "    'Salmon', 'Tan', 'HoneyDew', 'HotPink', 'IndianRed', 'Ivory', 'Khaki',\n",
    "    'Lavender', 'LavenderBlush', 'LawnGreen', 'LemonChiffon', 'LightBlue',\n",
    "    'LightCoral', 'LightCyan', 'LightGoldenRodYellow', 'LightGray', 'LightGrey',\n",
    "    'LightGreen', 'LightPink', 'LightSalmon', 'LightSeaGreen', 'LightSkyBlue',\n",
    "    'LightSlateGray', 'LightSlateGrey', 'LightSteelBlue', 'LightYellow', 'Lime',\n",
    "    'LimeGreen', 'Linen', 'Magenta', 'MediumAquaMarine', 'MediumOrchid',\n",
    "    'MediumPurple', 'MediumSeaGreen', 'MediumSlateBlue', 'MediumSpringGreen',\n",
    "    'MediumTurquoise', 'MediumVioletRed', 'MintCream', 'MistyRose', 'Moccasin',\n",
    "    'NavajoWhite', 'OldLace', 'Olive', 'OliveDrab', 'Orange', 'OrangeRed',\n",
    "    'Orchid', 'PaleGoldenRod', 'PaleGreen', 'PaleTurquoise', 'PaleVioletRed',\n",
    "    'PapayaWhip', 'PeachPuff', 'Peru', 'Pink', 'Plum', 'PowderBlue', 'Purple',\n",
    "    'Red', 'RosyBrown', 'RoyalBlue', 'SaddleBrown', 'Green', 'SandyBrown',\n",
    "    'SeaGreen', 'SeaShell', 'Sienna', 'Silver', 'SkyBlue', 'SlateBlue',\n",
    "    'SlateGray', 'SlateGrey', 'Snow', 'SpringGreen', 'SteelBlue', 'GreenYellow',\n",
    "    'Teal', 'Thistle', 'Tomato', 'Turquoise', 'Violet', 'Wheat', 'White',\n",
    "    'WhiteSmoke', 'Yellow', 'YellowGreen'\n",
    "]\n",
    "\n",
    "def visualize_boxes_and_labels_on_image_array(\n",
    "    image,\n",
    "    boxes,\n",
    "    classes,\n",
    "    scores,\n",
    "    category_index,\n",
    "    use_normalized_coordinates=False,\n",
    "    max_boxes_to_draw=20,\n",
    "    min_score_thresh=.5,\n",
    "    agnostic_mode=False,\n",
    "    line_thickness=4,\n",
    "    font_size=24,\n",
    "    mask_alpha=.4,\n",
    "    groundtruth_box_visualization_color='black'):\n",
    "\n",
    "  # Create a display string (and color) for every box location, group any boxes\n",
    "  # that correspond to the same location.\n",
    "  box_to_display_str_map = collections.defaultdict(list)\n",
    "  box_to_color_map = collections.defaultdict(str)\n",
    "  box_to_track_ids_map = {}\n",
    "  if not max_boxes_to_draw:\n",
    "    max_boxes_to_draw = boxes.shape[0]\n",
    "  for i in range(boxes.shape[0]):\n",
    "    if max_boxes_to_draw == len(box_to_color_map):\n",
    "      break\n",
    "    if scores is None or scores[i] > min_score_thresh:\n",
    "      box = tuple(boxes[i].tolist())\n",
    "      if scores is None:\n",
    "        box_to_color_map[box] = groundtruth_box_visualization_color\n",
    "      else:\n",
    "        display_str = ''\n",
    "        if not agnostic_mode:\n",
    "            if classes[i] in six.viewkeys(category_index):\n",
    "              class_name = category_index[classes[i]]['name']\n",
    "            else:\n",
    "              class_name = 'N/A'\n",
    "            display_str = str(class_name)\n",
    "        if not display_str:\n",
    "            display_str = '{}%'.format(round(100*scores[i]))\n",
    "        else:\n",
    "            display_str = '{}: {}%'.format(display_str, round(100*scores[i]))\n",
    "        box_to_display_str_map[box].append(display_str)\n",
    "        if agnostic_mode:\n",
    "          box_to_color_map[box] = 'DarkOrange'\n",
    "        else:\n",
    "          box_to_color_map[box] = STANDARD_COLORS[\n",
    "              classes[i] % len(STANDARD_COLORS)]\n",
    "\n",
    "  # Draw all boxes onto image.\n",
    "  for box, color in box_to_color_map.items():\n",
    "    ymin, xmin, ymax, xmax = box\n",
    "    draw_bounding_box_on_image_array(\n",
    "        image,\n",
    "        ymin,\n",
    "        xmin,\n",
    "        ymax,\n",
    "        xmax,\n",
    "        color=color,\n",
    "        thickness=line_thickness,\n",
    "        font_size=font_size,\n",
    "        display_str_list=box_to_display_str_map[box],\n",
    "        use_normalized_coordinates=use_normalized_coordinates)\n",
    "\n",
    "  return image\n",
    "\n",
    "def draw_bounding_box_on_image_array(\n",
    "    image,\n",
    "    ymin,\n",
    "    xmin,\n",
    "    ymax,\n",
    "    xmax,\n",
    "    color='red',\n",
    "    thickness=4,\n",
    "    font_size=24,\n",
    "    display_str_list=(),\n",
    "    use_normalized_coordinates=True):\n",
    "\n",
    "  image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "  draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color,\n",
    "                             thickness, font_size, display_str_list,\n",
    "                             use_normalized_coordinates)\n",
    "  np.copyto(image, np.array(image_pil))\n",
    "\n",
    "def draw_bounding_box_on_image(\n",
    "    image,\n",
    "    ymin,\n",
    "    xmin,\n",
    "    ymax,\n",
    "    xmax,\n",
    "    color='red',\n",
    "    thickness=4,\n",
    "    font_size=24,\n",
    "    display_str_list=(),\n",
    "    use_normalized_coordinates=True):\n",
    "\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  if use_normalized_coordinates:\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "  else:\n",
    "    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n",
    "  if thickness > 0:\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "               (left, top)],\n",
    "              width=thickness,\n",
    "              fill=color)\n",
    "  try:\n",
    "    font = ImageFont.truetype('arial.ttf', font_size)\n",
    "  except IOError:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "  # If the total height of the display strings added to the top of the bounding\n",
    "  # box exceeds the top of the image, stack the strings below the bounding box\n",
    "  # instead of above.\n",
    "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "  # Each display_str has a top and bottom margin of 0.05x.\n",
    "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "  if top > total_display_str_height:\n",
    "    text_bottom = top\n",
    "  else:\n",
    "    text_bottom = bottom + total_display_str_height\n",
    "  # Reverse list and print from bottom to top.\n",
    "  for display_str in display_str_list[::-1]:\n",
    "    text_width, text_height = font.getsize(display_str)\n",
    "    margin = np.ceil(0.05 * text_height)\n",
    "    draw.rectangle(\n",
    "        [(left, text_bottom - text_height - 2 * margin), (left + text_width,\n",
    "                                                          text_bottom)],\n",
    "        fill=color)\n",
    "    draw.text(\n",
    "        (left + margin, text_bottom - text_height - margin),\n",
    "        display_str,\n",
    "        fill='black',\n",
    "        font=font)\n",
    "    text_bottom -= text_height - 2 * margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0afc043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw detections on copied image\n",
    "for image in IMAGES_WITH_DETECTION:\n",
    "    visualize_boxes_and_labels_on_image_array(\n",
    "          image['image'][0],\n",
    "          image['detection']['detection_boxes'][0],\n",
    "          (image['detection']['detection_classes'][0]).astype(int),\n",
    "          image['detection']['detection_scores'][0],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          # Change this if confidence score should be higher or lower\n",
    "          min_score_thresh=.50,\n",
    "          line_thickness=6,\n",
    "          font_size=42,\n",
    "          agnostic_mode=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bff9ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display images with detection\n",
    "@widgets.interact(i=(0, len(IMAGES_WITH_DETECTION)))\n",
    "def show_image_at(i=0):\n",
    "    plt.figure(figsize=(24,32))\n",
    "    plt.imshow(IMAGES_WITH_DETECTION[i]['image'][0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0cc8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add output sub-directory named after the model that was used (if it doesn't already exist)\n",
    "output_dir = 'outputs/' + model_display_name + '/' + image_type + '/'\n",
    "pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "progress_save = widgets.IntProgress(min=0, max=len(IMAGES_WITH_DETECTION), description='Saved: ')\n",
    "save_label = widgets.Label(value='0 / ' + str(len(IMAGES_WITH_DETECTION)))\n",
    "display(widgets.HBox([progress_save, save_label]))\n",
    "\n",
    "# Save images\n",
    "for image in IMAGES_WITH_DETECTION:\n",
    "    plt.imsave(output_dir + image['filename'], image['image'][0], format='jpg')\n",
    "    \n",
    "    progress_save.value += 1\n",
    "    save_label.value = str(progress_save.value) + ' / ' + str(len(IMAGES_WITH_DETECTION))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
