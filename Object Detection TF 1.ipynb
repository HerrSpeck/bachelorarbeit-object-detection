{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa34e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and libs\n",
    "import os\n",
    "import os.path\n",
    "import pathlib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageOps\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import time\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e41a6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a4c2507",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_MODELS = {\n",
    "    # ImageNet datasets\n",
    "    'OpenImages Inception Resnet' : 'https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4536c3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4dbc7724a814f4283a5602e260e725e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loaded: ', max=99), Label(value='0 / 99')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load images from inputs folder\n",
    "IMAGES = []\n",
    "VALID_PATHS = []\n",
    "running = []\n",
    "\n",
    "# Get all valid image paths\n",
    "file_path = 'inputs/colorized_stable/' # use colorized_artistic for artistic model\n",
    "for image_path in os.listdir(file_path):\n",
    "    if (image_path.endswith('.jpg')):\n",
    "        # Collect image as valid path\n",
    "        VALID_PATHS.append(image_path)\n",
    "        \n",
    "progress_load = widgets.IntProgress(min=0, max=len(VALID_PATHS), description='Loaded: ') # instantiate the bar\n",
    "load_label = widgets.Label(value='0 / ' + str(len(VALID_PATHS)))\n",
    "display(widgets.HBox([progress_load, load_label])) # display the bar\n",
    "\n",
    "# Load given image into numpy array using matplotlib imload\n",
    "def load_valid_image(path):\n",
    "    img = mpimg.imread(file_path + path, format='jpg')\n",
    "    # Reshape image array to fit specifications required by tensorflow model\n",
    "    (rows, columns, channels) = img.shape\n",
    "    IMAGES.append({\n",
    "        'image': img.reshape((1, rows, columns, channels)),\n",
    "        'filename': path,\n",
    "        'detection': {}\n",
    "    })\n",
    "    progress_load.value += 1\n",
    "    load_label.value = str(progress_load.value) + ' / ' + str(len(VALID_PATHS))\n",
    "\n",
    "# Parallelize execution with threadpool\n",
    "def run_with_Threadpool(paths):\n",
    "    with ThreadPoolExecutor(max_workers=(os.cpu_count() * 5)) as executor:\n",
    "        # Schedule task for each image\n",
    "        running = [executor.submit(\n",
    "            lambda: load_valid_image(path)\n",
    "        ) for path in paths]\n",
    "\n",
    "\"\"\"\n",
    "    Since we are working with a lot of IO operations, we use Threadpool since it is much faster for IO than using Processes:\n",
    "    \n",
    "    Loading 20 images:\n",
    "        Runtime with Processes: ~20 seconds\n",
    "        Runtime with Threadpool: ~3 seconds\n",
    "\"\"\"\n",
    "# Load all valid images\n",
    "# start_time = time.time()\n",
    "# run_with_Threadpool(VALID_PATHS)\n",
    "# print(\"--- Runtime with Threadpool: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "for path in VALID_PATHS:\n",
    "    load_valid_image(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9581355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load object detection lib\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b9a687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to predefined labels for the open image dataset\n",
    "PATH_TO_LABELS = './tensorflow_models/research/object_detection/data/oid_v4_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "931a3e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model: OpenImages Inception Resnet\n",
      "Model Handle at TensorFlow Hub: https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\n",
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "# Select model\n",
    "model_display_name = 'OpenImages Inception Resnet'\n",
    "model_handle = ALL_MODELS[model_display_name]\n",
    "\n",
    "print('Selected model: '+ model_display_name)\n",
    "print('Model Handle at TensorFlow Hub: {}'.format(model_handle))\n",
    "\n",
    "# Load model\n",
    "hub_model = hub.load(model_handle).signatures['default']\n",
    "print('Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df229938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "  fig = plt.figure(figsize=(20, 15))\n",
    "  plt.grid(False)\n",
    "  plt.imshow(image)\n",
    "\n",
    "\n",
    "def download_and_resize_image(url, new_width=256, new_height=256,\n",
    "                              display=False):\n",
    "  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
    "  response = urlopen(url)\n",
    "  image_data = response.read()\n",
    "  image_data = BytesIO(image_data)\n",
    "  pil_image = Image.open(image_data)\n",
    "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
    "  pil_image_rgb = pil_image.convert(\"RGB\")\n",
    "  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
    "  print(\"Image downloaded to %s.\" % filename)\n",
    "  if display:\n",
    "    display_image(pil_image)\n",
    "  return filename\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color,\n",
    "                               font,\n",
    "                               thickness=4,\n",
    "                               display_str_list=()):\n",
    "  \"\"\"Adds a bounding box to an image.\"\"\"\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                ymin * im_height, ymax * im_height)\n",
    "  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "             (left, top)],\n",
    "            width=thickness,\n",
    "            fill=color)\n",
    "\n",
    "  # If the total height of the display strings added to the top of the bounding\n",
    "  # box exceeds the top of the image, stack the strings below the bounding box\n",
    "  # instead of above.\n",
    "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "  # Each display_str has a top and bottom margin of 0.05x.\n",
    "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "  if top > total_display_str_height:\n",
    "    text_bottom = top\n",
    "  else:\n",
    "    text_bottom = top + total_display_str_height\n",
    "  # Reverse list and print from bottom to top.\n",
    "  for display_str in display_str_list[::-1]:\n",
    "    text_width, text_height = font.getsize(display_str)\n",
    "    margin = np.ceil(0.05 * text_height)\n",
    "    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
    "                    (left + text_width, text_bottom)],\n",
    "                   fill=color)\n",
    "    draw.text((left + margin, text_bottom - text_height - margin),\n",
    "              display_str,\n",
    "              fill=\"black\",\n",
    "              font=font)\n",
    "    text_bottom -= text_height - 2 * margin\n",
    "\n",
    "\n",
    "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.5):\n",
    "  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
    "  colors = list(ImageColor.colormap.values())\n",
    "\n",
    "  try:\n",
    "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n",
    "                              25)\n",
    "  except IOError:\n",
    "    print(\"Font not found, using default font.\")\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "  for i in range(min(boxes.shape[0], max_boxes)):\n",
    "    if scores[i] >= min_score:\n",
    "      ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
    "                                     int(100 * scores[i]))\n",
    "      color = colors[hash(class_names[i]) % len(colors)]\n",
    "      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
    "      draw_bounding_box_on_image(\n",
    "          image_pil,\n",
    "          ymin,\n",
    "          xmin,\n",
    "          ymax,\n",
    "          xmax,\n",
    "          color,\n",
    "          font,\n",
    "          display_str_list=[display_str])\n",
    "      np.copyto(image, np.array(image_pil))\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f2d97d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357f509fa8c74f6ab5d0be2154dd4397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Inferred: ', max=99), Label(value='0 / 99')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Runtime: 3.05 minutes ---\n"
     ]
    }
   ],
   "source": [
    "# running inference\n",
    "# different object detection models have additional results\n",
    "# all of them are explained in the documentation\n",
    "progress_inference = widgets.IntProgress(min=0, max=len(IMAGES), description='Inferred: ')\n",
    "inference_label = widgets.Label(value='0 / ' + str(len(IMAGES)))\n",
    "display(widgets.HBox([progress_inference, inference_label]))\n",
    "\n",
    "start_time = time.time()\n",
    "for image in IMAGES:\n",
    "    # Run object detection and save results\n",
    "    converted = tf.image.convert_image_dtype(image['image'], tf.float32)\n",
    "    detected = hub_model(converted)\n",
    "    image['detection'] = {key:value.numpy() for key,value in detected.items()}\n",
    "    \n",
    "    progress_inference.value += 1\n",
    "    inference_label.value = str(progress_inference.value) + ' / ' + str(len(IMAGES))\n",
    "    \n",
    "runtime = ((time.time() - start_time) / 60)\n",
    "print(\"--- Runtime: \" + f'{runtime:.2f}' + \" minutes ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfb46991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy image to draw detected objects\n",
    "IMAGES_WITH_DETECTION = []\n",
    "for image in IMAGES:\n",
    "    IMAGES_WITH_DETECTION.append({\n",
    "        'image': image['image'].copy(),\n",
    "        'filename': image['filename'],\n",
    "        'detection': image['detection']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b185720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4eb034c4ad4f1c874a4b4c9c5e4d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=99), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw detections on copied image\n",
    "#IMAGES_WITH_DETECTION = []\n",
    "#for image in IMAGES:\n",
    "#    IMAGES_WITH_DETECTION.append(draw_boxes(\n",
    "#        image['image'], image['detection']['detection_boxes'],\n",
    "#        image['detection']['detection_class_entities'], image['detection']['detection_scores']\n",
    "#    ))\n",
    "    \n",
    "# Draw detections on copied image\n",
    "for image in IMAGES_WITH_DETECTION:\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image['image'][0],\n",
    "          image['detection']['detection_boxes'],\n",
    "          (image['detection']['detection_class_labels']).astype(int),\n",
    "          image['detection']['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          # Change this if confidence score should be higher or lower\n",
    "          min_score_thresh=.50,\n",
    "          line_thickness=6,\n",
    "          agnostic_mode=False\n",
    "    )\n",
    "\n",
    "# Draw first new image\n",
    "@widgets.interact(i=(0, len(IMAGES_WITH_DETECTION)))\n",
    "def show_image_at(i=0):\n",
    "    plt.figure(figsize=(24,32))\n",
    "    plt.imshow(IMAGES_WITH_DETECTION[i]['image'][0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e35d9598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e1679ab3c741f6ab3ea15de42a5d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Saved: ', max=99), Label(value='0 / 99')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add output sub-directory named after the model that was used (if it doesn't already exist)\n",
    "output_dir = 'outputs/' + model_display_name + '/'\n",
    "pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "progress_save = widgets.IntProgress(min=0, max=len(IMAGES_WITH_DETECTION), description='Saved: ')\n",
    "save_label = widgets.Label(value='0 / ' + str(len(IMAGES_WITH_DETECTION)))\n",
    "display(widgets.HBox([progress_save, save_label]))\n",
    "\n",
    "# Save images\n",
    "for image in IMAGES_WITH_DETECTION:\n",
    "    plt.imsave(output_dir + image['filename'], image['image'][0], format='jpg')\n",
    "    \n",
    "    progress_save.value += 1\n",
    "    save_label.value = str(progress_save.value) + ' / ' + str(len(IMAGES_WITH_DETECTION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf0d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
