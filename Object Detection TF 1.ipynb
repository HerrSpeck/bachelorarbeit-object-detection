{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa34e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and libs\n",
    "import os\n",
    "import os.path\n",
    "import pathlib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageOps\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import time\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e41a6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a4c2507",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_MODELS = {\n",
    "    # ImageNet datasets\n",
    "    'Faster R-CNN (OpenImages)' : 'https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9581355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load object detection lib\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b9a687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to predefined labels for the open image dataset\n",
    "PATH_TO_LABELS = './tensorflow_models/research/object_detection/data/oid_v4_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "931a3e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model: Faster R-CNN Inception ResNet V2 1024x1024 (OpenImages)\n",
      "Model Handle at TensorFlow Hub: https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\n",
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "# Select model\n",
    "model_display_name = 'Faster R-CNN Inception ResNet V2 1024x1024 (OpenImages)'\n",
    "model_handle = ALL_MODELS[model_display_name]\n",
    "\n",
    "print('Selected model: '+ model_display_name)\n",
    "print('Model Handle at TensorFlow Hub: {}'.format(model_handle))\n",
    "\n",
    "# Load model\n",
    "hub_model = hub.load(model_handle).signatures['default']\n",
    "print('Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df229938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from inputs folder\n",
    "IMAGES = []\n",
    "VALID_PATHS = []\n",
    "running = []\n",
    "\n",
    "# Get all valid image paths\n",
    "# image_type = 'colorized_artistic' # use this for brighter/more daring colors\n",
    "# image_type = 'grayscale' # use this for the original grayscale images\n",
    "image_type = 'colorized_stable' # use this for most stable results\n",
    "file_path = 'inputs/' + image_type + '/'\n",
    "for image_path in os.listdir(file_path):\n",
    "    if (image_path.endswith('.jpg')):\n",
    "        # Collect image as valid path\n",
    "        VALID_PATHS.append(image_path)\n",
    "        \n",
    "progress_load = widgets.IntProgress(min=0, max=len(VALID_PATHS), description='Loaded: ') # instantiate the bar\n",
    "load_label = widgets.Label(value='0 / ' + str(len(VALID_PATHS)))\n",
    "display(widgets.HBox([progress_load, load_label])) # display the bar\n",
    "\n",
    "# Load given image into numpy array using matplotlib imload\n",
    "def load_valid_image(path):\n",
    "    img = mpimg.imread(file_path + path, format='jpg')\n",
    "    # Reshape image array to fit specifications required by tensorflow model\n",
    "    (rows, columns, channels) = img.shape\n",
    "    IMAGES.append({\n",
    "        'image': img.reshape((1, rows, columns, channels)),\n",
    "        'filename': path,\n",
    "        'detection': {}\n",
    "    })\n",
    "    progress_load.value += 1\n",
    "    load_label.value = str(progress_load.value) + ' / ' + str(len(VALID_PATHS))\n",
    "\n",
    "# Parallelize execution with threadpool\n",
    "def run_with_Threadpool(paths):\n",
    "    with ThreadPoolExecutor(max_workers=(os.cpu_count() * 5)) as executor:\n",
    "        # Schedule task for each image\n",
    "        running = [executor.submit(\n",
    "            lambda: load_valid_image(path)\n",
    "        ) for path in paths]\n",
    "\n",
    "\"\"\"\n",
    "    Since we are working with a lot of IO operations, we use Threadpool since it is much faster for IO than using Processes:\n",
    "    \n",
    "    Loading 20 images:\n",
    "        Runtime with Processes: ~20 seconds\n",
    "        Runtime with Threadpool: ~3 seconds\n",
    "\"\"\"\n",
    "# Load all valid images\n",
    "# start_time = time.time()\n",
    "# run_with_Threadpool(VALID_PATHS)\n",
    "# print(\"--- Runtime with Threadpool: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "for path in VALID_PATHS:\n",
    "    load_valid_image(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f2d97d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ae7d9cd7f54adf8a215afd641b6622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Inferred: ', max=99), Label(value='0 / 99')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Runtime: 3.03 minutes ---\n"
     ]
    }
   ],
   "source": [
    "# running inference\n",
    "# different object detection models have additional results\n",
    "# all of them are explained in the documentation\n",
    "progress_inference = widgets.IntProgress(min=0, max=len(IMAGES), description='Inferred: ')\n",
    "inference_label = widgets.Label(value='0 / ' + str(len(IMAGES)))\n",
    "display(widgets.HBox([progress_inference, inference_label]))\n",
    "\n",
    "start_time = time.time()\n",
    "for image in IMAGES:\n",
    "    # Run object detection and save results\n",
    "    converted = tf.image.convert_image_dtype(image['image'], tf.float32)\n",
    "    detected = hub_model(converted)\n",
    "    image['detection'] = {key:value.numpy() for key,value in detected.items()}\n",
    "    \n",
    "    progress_inference.value += 1\n",
    "    inference_label.value = str(progress_inference.value) + ' / ' + str(len(IMAGES))\n",
    "    \n",
    "runtime = ((time.time() - start_time) / 60)\n",
    "print(\"--- Runtime: \" + f'{runtime:.2f}' + \" minutes ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfb46991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy image to draw detected objects\n",
    "IMAGES_WITH_DETECTION = []\n",
    "for image in IMAGES:\n",
    "    IMAGES_WITH_DETECTION.append({\n",
    "        'image': image['image'].copy(),\n",
    "        'filename': image['filename'],\n",
    "        'detection': image['detection']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b185720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624267ce9ca84ae3a2427d429ee0c789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=99), Output()), _dom_classes=('widget-interact',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw detections on copied image\n",
    "for image in IMAGES_WITH_DETECTION:\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image['image'][0],\n",
    "          image['detection']['detection_boxes'],\n",
    "          (image['detection']['detection_class_labels']).astype(int),\n",
    "          image['detection']['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          # Change this if confidence score should be higher or lower\n",
    "          min_score_thresh=.50,\n",
    "          line_thickness=6,\n",
    "          agnostic_mode=False,\n",
    "          font_size=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a038abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display images with detection\n",
    "@widgets.interact(i=(0, len(IMAGES_WITH_DETECTION)))\n",
    "def show_image_at(i=0):\n",
    "    plt.figure(figsize=(24,32))\n",
    "    plt.imshow(IMAGES_WITH_DETECTION[i]['image'][0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e35d9598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ca243d1066489890a98d85247b86d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Saved: ', max=99), Label(value='0 / 99')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add output sub-directory named after the model that was used (if it doesn't already exist)\n",
    "output_dir = 'outputs/' + model_display_name + '/' + image_type + '/'\n",
    "pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "progress_save = widgets.IntProgress(min=0, max=len(IMAGES_WITH_DETECTION), description='Saved: ')\n",
    "save_label = widgets.Label(value='0 / ' + str(len(IMAGES_WITH_DETECTION)))\n",
    "display(widgets.HBox([progress_save, save_label]))\n",
    "\n",
    "# Save images\n",
    "for image in IMAGES_WITH_DETECTION:\n",
    "    plt.imsave(output_dir + image['filename'], image['image'][0], format='jpg')\n",
    "    \n",
    "    progress_save.value += 1\n",
    "    save_label.value = str(progress_save.value) + ' / ' + str(len(IMAGES_WITH_DETECTION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf0d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
