{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a7780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and libs\n",
    "import os\n",
    "import os.path\n",
    "import pathlib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import PIL.Image as Image\n",
    "import PIL.ImageColor as ImageColor\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import PIL.ImageFont as ImageFont\n",
    "\n",
    "import six\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import collections\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import time\n",
    "\n",
    "# Load object detection lib\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "%matplotlib inline\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3349f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "USE_LEGACY = False\n",
    "PATH_TO_LABELS = './tensorflow_models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "CATEGORY_INDEX = None\n",
    "ALL_MODELS = {\n",
    "    'EfficientDet' : 'https://tfhub.dev/tensorflow/efficientdet/d7/1',\n",
    "    'Faster R-CNN' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1',\n",
    "    'Faster R-CNN (OpenImages)' : 'https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1',\n",
    "    'CenterNet' : 'https://tfhub.dev/tensorflow/centernet/resnet101v1_fpn_512x512/1'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d516e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Faster R-CNN (Open Images) model requires use of legacy code, so set the value accordingly\n",
    "def set_legacy(use_legacy):\n",
    "    global USE_LEGACY, PATH_TO_LABELS, CATEGORY_INDEX\n",
    "    \n",
    "    USE_LEGACY = use_legacy\n",
    "    if USE_LEGACY:\n",
    "        tf.config.run_functions_eagerly(True)\n",
    "        PATH_TO_LABELS = './tensorflow_models/research/object_detection/data/oid_v4_label_map.pbtxt'\n",
    "    else:\n",
    "        tf.config.run_functions_eagerly(False)\n",
    "        PATH_TO_LABELS = './tensorflow_models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "    CATEGORY_INDEX = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4142c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "def load_model(model_handle):\n",
    "    if USE_LEGACY:\n",
    "        hub_model = hub.load(model_handle).signatures['default']\n",
    "    else:\n",
    "        hub_model = hub.load(model_handle)\n",
    "    \n",
    "    print('Model loaded!')\n",
    "    \n",
    "    return hub_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ccc0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all valid image paths\n",
    "# use image_type = 'colorized_artistic' for brighter/more daring colors\n",
    "# use image_type = 'grayscale' for the original grayscale images\n",
    "def get_valid_image_paths(path):\n",
    "    valid_paths = []\n",
    "    for image_path in os.listdir(path):\n",
    "        if (image_path.endswith('.jpg')):\n",
    "            # Collect image as valid path\n",
    "            valid_paths.append(image_path)\n",
    "    return valid_paths\n",
    "\n",
    "# Load given image into numpy array using matplotlib imload\n",
    "def load_valid_image(path, filename):\n",
    "    img = mpimg.imread(path + filename, format='jpg')\n",
    "    # Reshape image array to fit specifications required by tensorflow model\n",
    "    (rows, columns, channels) = img.shape\n",
    "    image = {\n",
    "        'image': img.reshape((1, rows, columns, channels)),\n",
    "        'filename': filename\n",
    "    }\n",
    "    return image\n",
    "\n",
    "# The images are objects of the shape:\n",
    "# {\n",
    "#     'image': Actual Image Object,\n",
    "#     'filename': Name of the original image\n",
    "# }\n",
    "def load_images(image_type='colorized_stable'):\n",
    "    path = 'inputs/' + image_type + '/'\n",
    "    valid_paths = get_valid_image_paths(path)\n",
    "    \n",
    "    # How many images were loaded so far\n",
    "    progress_load = widgets.IntProgress(min=0, max=len(valid_paths), description='Loaded: ') # instantiate the bar\n",
    "    load_label = widgets.Label(value='0 / ' + str(len(valid_paths)))\n",
    "    display(widgets.HBox([progress_load, load_label])) # display the bar\n",
    "    \n",
    "    images = []\n",
    "    for filename in valid_paths:\n",
    "        images.append(load_valid_image(path, filename))\n",
    "        \n",
    "        progress_load.value += 1\n",
    "        load_label.value = str(progress_load.value) + ' / ' + str(len(valid_paths))\n",
    "        \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6bf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference with selected model on given images\n",
    "# The array of images that was returned contains objects of the shape:\n",
    "# {\n",
    "#     'image': Actual Image Object,\n",
    "#     'filename': Name of the original image\n",
    "#     'detection': Detected objects on the image\n",
    "# }\n",
    "def run_inference(images, model):\n",
    "    # How many images were used for inference so far\n",
    "    progress_inference = widgets.IntProgress(min=0, max=len(images), description='Inferred: ')\n",
    "    inference_label = widgets.Label(value='0 / ' + str(len(images)))\n",
    "    display(widgets.HBox([progress_inference, inference_label]))\n",
    "    \n",
    "    images_with_detection = []\n",
    "    \n",
    "    for image in images:\n",
    "        # Run object detection and save results\n",
    "        if USE_LEGACY:\n",
    "            converted = tf.image.convert_image_dtype(image['image'], tf.float32)\n",
    "        else:\n",
    "            converted = image['image']\n",
    "        detected = model(converted)\n",
    "        \n",
    "        images_with_detection.append({\n",
    "            'image': image['image'].copy(),\n",
    "            'filename': image['filename'],\n",
    "            'detection': {key:value.numpy() for key,value in detected.items()}\n",
    "        })\n",
    "\n",
    "        progress_inference.value += 1\n",
    "        inference_label.value = str(progress_inference.value) + ' / ' + str(len(images))\n",
    "    \n",
    "    return images_with_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fbf58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a shortened version of the tensorflow library function to visualize detections on images\n",
    "# It has been shortened/adapted to support the use of variable font-sized based on the images dimensions\n",
    "STANDARD_COLORS = [\n",
    "    'AliceBlue', 'Chartreuse', 'Aqua', 'Aquamarine', 'Azure', 'Beige', 'Bisque',\n",
    "    'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue', 'AntiqueWhite',\n",
    "    'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson', 'Cyan',\n",
    "    'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n",
    "    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet',\n",
    "    'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n",
    "    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'Gold', 'GoldenRod',\n",
    "    'Salmon', 'Tan', 'HoneyDew', 'HotPink', 'IndianRed', 'Ivory', 'Khaki',\n",
    "    'Lavender', 'LavenderBlush', 'LawnGreen', 'LemonChiffon', 'LightBlue',\n",
    "    'LightCoral', 'LightCyan', 'LightGoldenRodYellow', 'LightGray', 'LightGrey',\n",
    "    'LightGreen', 'LightPink', 'LightSalmon', 'LightSeaGreen', 'LightSkyBlue',\n",
    "    'LightSlateGray', 'LightSlateGrey', 'LightSteelBlue', 'LightYellow', 'Lime',\n",
    "    'LimeGreen', 'Linen', 'Magenta', 'MediumAquaMarine', 'MediumOrchid',\n",
    "    'MediumPurple', 'MediumSeaGreen', 'MediumSlateBlue', 'MediumSpringGreen',\n",
    "    'MediumTurquoise', 'MediumVioletRed', 'MintCream', 'MistyRose', 'Moccasin',\n",
    "    'NavajoWhite', 'OldLace', 'Olive', 'OliveDrab', 'Orange', 'OrangeRed',\n",
    "    'Orchid', 'PaleGoldenRod', 'PaleGreen', 'PaleTurquoise', 'PaleVioletRed',\n",
    "    'PapayaWhip', 'PeachPuff', 'Peru', 'Pink', 'Plum', 'PowderBlue', 'Purple',\n",
    "    'Red', 'RosyBrown', 'RoyalBlue', 'SaddleBrown', 'Green', 'SandyBrown',\n",
    "    'SeaGreen', 'SeaShell', 'Sienna', 'Silver', 'SkyBlue', 'SlateBlue',\n",
    "    'SlateGray', 'SlateGrey', 'Snow', 'SpringGreen', 'SteelBlue', 'GreenYellow',\n",
    "    'Teal', 'Thistle', 'Tomato', 'Turquoise', 'Violet', 'Wheat', 'White',\n",
    "    'WhiteSmoke', 'Yellow', 'YellowGreen'\n",
    "]\n",
    "\n",
    "def visualize_boxes_and_labels_on_image_array(\n",
    "    image,\n",
    "    boxes,\n",
    "    classes,\n",
    "    scores,\n",
    "    category_index,\n",
    "    use_normalized_coordinates=False,\n",
    "    max_boxes_to_draw=20,\n",
    "    min_score_thresh=.5,\n",
    "    agnostic_mode=False,\n",
    "    line_thickness=4,\n",
    "    font_size=24,\n",
    "    mask_alpha=.4,\n",
    "    groundtruth_box_visualization_color='black'):\n",
    "\n",
    "  # Create a display string (and color) for every box location, group any boxes\n",
    "  # that correspond to the same location.\n",
    "  box_to_display_str_map = collections.defaultdict(list)\n",
    "  box_to_color_map = collections.defaultdict(str)\n",
    "  box_to_track_ids_map = {}\n",
    "  if not max_boxes_to_draw:\n",
    "    max_boxes_to_draw = boxes.shape[0]\n",
    "  for i in range(boxes.shape[0]):\n",
    "    if max_boxes_to_draw == len(box_to_color_map):\n",
    "      break\n",
    "    if scores is None or scores[i] > min_score_thresh:\n",
    "      box = tuple(boxes[i].tolist())\n",
    "      if scores is None:\n",
    "        box_to_color_map[box] = groundtruth_box_visualization_color\n",
    "      else:\n",
    "        display_str = ''\n",
    "        if not agnostic_mode:\n",
    "            if classes[i] in six.viewkeys(category_index):\n",
    "              class_name = category_index[classes[i]]['name']\n",
    "            else:\n",
    "              class_name = 'N/A'\n",
    "            display_str = str(class_name) + ' '\n",
    "        box_to_display_str_map[box].append(display_str)\n",
    "        if agnostic_mode:\n",
    "          box_to_color_map[box] = 'DarkOrange'\n",
    "        else:\n",
    "          box_to_color_map[box] = STANDARD_COLORS[\n",
    "              classes[i] % len(STANDARD_COLORS)]\n",
    "\n",
    "  # Draw all boxes onto image.\n",
    "  for box, color in box_to_color_map.items():\n",
    "    ymin, xmin, ymax, xmax = box\n",
    "    draw_bounding_box_on_image_array(\n",
    "        image,\n",
    "        ymin,\n",
    "        xmin,\n",
    "        ymax,\n",
    "        xmax,\n",
    "        color=color,\n",
    "        thickness=line_thickness,\n",
    "        font_size=font_size,\n",
    "        display_str_list=box_to_display_str_map[box],\n",
    "        use_normalized_coordinates=use_normalized_coordinates)\n",
    "\n",
    "  return image\n",
    "\n",
    "def draw_bounding_box_on_image_array(\n",
    "    image,\n",
    "    ymin,\n",
    "    xmin,\n",
    "    ymax,\n",
    "    xmax,\n",
    "    color='red',\n",
    "    thickness=4,\n",
    "    font_size=24,\n",
    "    display_str_list=(),\n",
    "    use_normalized_coordinates=True):\n",
    "\n",
    "  image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "  draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color,\n",
    "                             thickness, font_size, display_str_list,\n",
    "                             use_normalized_coordinates)\n",
    "  np.copyto(image, np.array(image_pil))\n",
    "\n",
    "def draw_bounding_box_on_image(\n",
    "    image,\n",
    "    ymin,\n",
    "    xmin,\n",
    "    ymax,\n",
    "    xmax,\n",
    "    color='red',\n",
    "    thickness=4,\n",
    "    font_size=24,\n",
    "    display_str_list=(),\n",
    "    use_normalized_coordinates=True):\n",
    "\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  if use_normalized_coordinates:\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "  else:\n",
    "    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n",
    "  if thickness > 0:\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "               (left, top)],\n",
    "              width=thickness,\n",
    "              fill=color)\n",
    "  try:\n",
    "    font = ImageFont.truetype('arial.ttf', font_size)\n",
    "  except IOError:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "  # If the total height of the display strings added to the top of the bounding\n",
    "  # box exceeds the top of the image, stack the strings below the bounding box\n",
    "  # instead of above.\n",
    "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "  # Each display_str has a top and bottom margin of 0.05x.\n",
    "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "  if top > total_display_str_height:\n",
    "    text_bottom = top\n",
    "  else:\n",
    "    text_bottom = bottom + total_display_str_height\n",
    "  # Reverse list and print from bottom to top.\n",
    "  for display_str in display_str_list[::-1]:\n",
    "    text_width, text_height = font.getsize(display_str)\n",
    "    margin = np.ceil(0.05 * text_height)\n",
    "    draw.rectangle(\n",
    "        [(left, text_bottom - text_height - 2 * margin), (left + text_width,\n",
    "                                                          text_bottom)],\n",
    "        fill=color)\n",
    "    draw.text(\n",
    "        (left + margin, text_bottom - text_height - margin),\n",
    "        display_str,\n",
    "        fill='black',\n",
    "        font=font)\n",
    "    text_bottom -= text_height - 2 * margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336c8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine how many objects were inferred and which object types for every image\n",
    "# The array that is returned will contain one object of the following shape:\n",
    "# {\n",
    "#     'class': count,\n",
    "#     'otherclass': othercount,\n",
    "#     ....\n",
    "# }\n",
    "# for each of the given images\n",
    "def get_detections_for_images(images):\n",
    "    all_detections = []\n",
    "    \n",
    "    print(USE_LEGACY)\n",
    "    for image in images:\n",
    "        detections = image['detection']\n",
    "        boxes = detections['detection_boxes'] if USE_LEGACY else detections['detection_boxes'][0]\n",
    "        max_boxes_to_draw = boxes.shape[0]\n",
    "        scores = detections['detection_scores'] if USE_LEGACY else detections['detection_scores'][0]\n",
    "        coordinates = {}\n",
    "        for i in range(min(max_boxes_to_draw, boxes.shape[0])):\n",
    "            if scores[i] > 0.5:\n",
    "                class_id = int(detections['detection_class_labels'][i]) if USE_LEGACY else int(detections['detection_classes'][0][i])\n",
    "                class_name = CATEGORY_INDEX[class_id]['name']\n",
    "\n",
    "                if class_name in coordinates:\n",
    "                    coordinates[class_name] += 1\n",
    "                else:\n",
    "                    coordinates[class_name] = 1\n",
    "        all_detections.append(coordinates)\n",
    "        \n",
    "    return all_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a5210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def font_size_for_width(width):\n",
    "    return int((width * 2) / 100)\n",
    "\n",
    "def line_width_for_width(width):\n",
    "    return int(np.log((width * 2) / 1000) * 5) + 1\n",
    "\n",
    "# Draw detections on copied image\n",
    "def draw_detections_on_images(images_with_detections):\n",
    "    # How many detections were visualized so far\n",
    "    progress_save = widgets.IntProgress(min=0, max=len(images_with_detections), description='Visualized: ')\n",
    "    save_label = widgets.Label(value='0 / ' + str(len(images_with_detections)))\n",
    "    display(widgets.HBox([progress_save, save_label]))\n",
    "    \n",
    "    for image in images_with_detections:\n",
    "        # Determine font size based on image width\n",
    "        (width, height, channels) = image['image'][0].shape\n",
    "\n",
    "        # Draw detections\n",
    "        visualize_boxes_and_labels_on_image_array(\n",
    "              image['image'][0],\n",
    "              image['detection']['detection_boxes'] if USE_LEGACY else image['detection']['detection_boxes'][0],\n",
    "              image['detection']['detection_class_labels'].astype(int) if USE_LEGACY else image['detection']['detection_classes'][0].astype(int),\n",
    "              image['detection']['detection_scores'] if USE_LEGACY else image['detection']['detection_scores'][0],\n",
    "              CATEGORY_INDEX,\n",
    "              use_normalized_coordinates=True,\n",
    "              max_boxes_to_draw=200,\n",
    "              # Change this if confidence score should be higher or lower\n",
    "              min_score_thresh=.50,\n",
    "              line_thickness=line_width_for_width(width),\n",
    "              font_size=font_size_for_width(width),\n",
    "              agnostic_mode=False\n",
    "        )\n",
    "\n",
    "        progress_save.value += 1\n",
    "        save_label.value = str(progress_save.value) + ' / ' + str(len(images_with_detections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677265ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add output sub-directory named after the model that was used (if it doesn't already exist)\n",
    "def save_images(images_with_detections, model_name):\n",
    "    # How many images were saved so far\n",
    "    progress_save = widgets.IntProgress(min=0, max=len(images_with_detections), description='Saved: ')\n",
    "    save_label = widgets.Label(value='0 / ' + str(len(images_with_detections)))\n",
    "    display(widgets.HBox([progress_save, save_label]))\n",
    "    \n",
    "    output_dir = 'outputs/' + model_name + '/'\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save images\n",
    "    for image in images_with_detections:\n",
    "        plt.imsave(output_dir + image['filename'], image['image'][0], format='jpg')\n",
    "\n",
    "        progress_save.value += 1\n",
    "        save_label.value = str(progress_save.value) + ' / ' + str(len(images_with_detections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6a460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you want statistics on all inferences run for each model\n",
    "# @param image_count: number of images that were used \n",
    "def get_statistics_for_detections(detections, image_count):\n",
    "    dataFrame = pd.DataFrame(detections, index=range(1, image_count + 1))\n",
    "\n",
    "    pathlib.Path('outputs/statistics/').mkdir(parents=True, exist_ok=True)\n",
    "    dataFrame.to_csv('outputs/statistics/detections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137924d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this for charts\n",
    "# @param image_count: number of images that were used\n",
    "def generate_detection_charts(all_detections, image_count):\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    \n",
    "    # Total detections per image\n",
    "    plt.subplot(221)\n",
    "    total_detections = {}\n",
    "    for model, detections in all_detections.items():\n",
    "        model_detections = [np.sum(list(x.values())) for x in detections]\n",
    "        total_detections[model] = np.sum(model_detections)\n",
    "        plt.plot(model_detections)\n",
    "    plt.ylabel('Detections per Image')\n",
    "    plt.xlabel('Image Index')\n",
    "    plt.legend(list(total_detections.keys()), loc='upper left')\n",
    "\n",
    "    # Average detections per image\n",
    "    plt.subplot(222)\n",
    "    plt.ylabel('Average Detections per Image')\n",
    "    plt.bar([name for name in total_detections.keys()], [value / image_count for value in total_detections.values()])\n",
    "\n",
    "    # Total detections\n",
    "    # plt.subplot(223)\n",
    "    # plt.ylabel('Total Detections')\n",
    "    # plt.bar([name for name in total_detections.keys()], [value for value in total_detections.values()])\n",
    "\n",
    "    plt.savefig('outputs/statistics/statistics.svg', format='svg')\n",
    "    plt.savefig('outputs/statistics/statistics.jpg', format='jpg')\n",
    "    plt.savefig('outputs/statistics/statistics.pgf', format='pgf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced00ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordcloud(detections):\n",
    "    all_classes = [key for keys in [list(c.keys()) for c in detections] for key in keys]\n",
    "    all_classes = ' '.join(all_classes)\n",
    "\n",
    "    return WordCloud(background_color='white', width=1920, height=1080).generate(all_classes)\n",
    "\n",
    "# Run this for a word cloud with the detected classes\n",
    "def generate_wordclouds_for_all_models(all_detections):\n",
    "    for model, detections in all_detections.items():\n",
    "        wordcloud = generate_wordcloud(detections)\n",
    "\n",
    "        # Show WordCloud\n",
    "        print(model + ':')\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis(False)\n",
    "        plt.show()\n",
    "\n",
    "        # Save WordCloud\n",
    "        wordcloud.to_file('outputs/statistics/' + model + '_wordcloud.jpg')\n",
    "        plt.savefig('outputs/statistics/' + model + '_wordcloud.svg', format='svg')\n",
    "        plt.savefig('outputs/statistics/' + model + '_wordcloud.pgf', format='pgf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78e4441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordclouds_by_dataset(all_detections):\n",
    "    detections_mscoco = [v2 for k, v1 in all_detections.items() if k != 'Faster R-CNN (OpenImages)' for v2 in v1]\n",
    "    \n",
    "    mscoco_wc = generate_wordcloud(detections_mscoco)\n",
    "    \n",
    "    # Show WordCloud\n",
    "    print('MS COCO:')\n",
    "    plt.imshow(mscoco_wc, interpolation='bilinear')\n",
    "    plt.axis(False)\n",
    "    plt.show()\n",
    "\n",
    "    # Save WordCloud\n",
    "    mscoco_wc.to_file('outputs/statistics/mscoco_wordcloud.jpg')\n",
    "    plt.savefig('outputs/statistics/mscoco_wordcloud.svg', format='svg')\n",
    "    plt.savefig('outputs/statistics/mscoco_wordcloud.pgf', format='pgf')\n",
    "    \n",
    "    openimages_wc = generate_wordcloud(all_detections['Faster R-CNN (OpenImages)'])\n",
    "    \n",
    "    # Show WordCloud\n",
    "    print('OpenImages V4:')\n",
    "    plt.imshow(openimages_wc, interpolation='bilinear')\n",
    "    plt.axis(False)\n",
    "    plt.show()\n",
    "\n",
    "    # Save WordCloud\n",
    "    openimages_wc.to_file('outputs/statistics/openimages_wordcloud.jpg')\n",
    "    plt.savefig('outputs/statistics/openimages_wordcloud.svg', format='svg')\n",
    "    plt.savefig('outputs/statistics/openimages_wordcloud.pgf', format='pgf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48054d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw first image\n",
    "# @widgets.interact(i=(0, len(IMAGES)))\n",
    "# def show_image_at(i=0):\n",
    "#     plt.figure(figsize=(18,26))\n",
    "#     plt.imshow(IMAGES[i]['image'][0])\n",
    "#     plt.show()\n",
    "    \n",
    "# Display images with detection\n",
    "# @widgets.interact(i=(0, len(IMAGES_WITH_DETECTION)))\n",
    "# def show_image_at(i=0):\n",
    "#     plt.figure(figsize=(24,32))\n",
    "#     plt.imshow(IMAGES_WITH_DETECTION[i]['image'][0])\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
