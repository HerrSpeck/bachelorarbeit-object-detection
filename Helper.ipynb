{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a7780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and libs\n",
    "import os\n",
    "import os.path\n",
    "import pathlib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import PIL.Image as Image\n",
    "import PIL.ImageColor as ImageColor\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import PIL.ImageFont as ImageFont\n",
    "\n",
    "import six\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import collections\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import time\n",
    "\n",
    "# Load object detection lib\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from urllib import request, parse\n",
    "import json\n",
    "import gzip\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import re\n",
    "\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "\n",
    "%matplotlib inline\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a674265",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('pgf')\n",
    "matplotlib.rcParams.update({\n",
    "    'pgf.texsystem': 'pdflatex',\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "    'font.size': 14,\n",
    "    'figure.figsize': (9,8)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3349f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "USE_LEGACY = False\n",
    "PATH_TO_LABELS = './tensorflow_models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "CATEGORY_INDEX = None\n",
    "ALL_MODELS = {\n",
    "    'EfficientDet' : 'https://tfhub.dev/tensorflow/efficientdet/d7/1',\n",
    "    'Faster R-CNN' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1',\n",
    "    'Faster R-CNN (OpenImages)' : 'https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1',\n",
    "    'CenterNet' : 'https://tfhub.dev/tensorflow/centernet/resnet101v1_fpn_512x512/1'\n",
    "}\n",
    "MODEL_NAME = 'EfficientDet'\n",
    "MODEL_HANDLE = 'https://tfhub.dev/tensorflow/efficientdet/d7/1'\n",
    "THRESHOLD = .5\n",
    "IMAGE_BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d516e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Faster R-CNN (Open Images) model requires use of legacy code, so set the value accordingly\n",
    "def set_legacy(use_legacy):\n",
    "    global USE_LEGACY, PATH_TO_LABELS, CATEGORY_INDEX\n",
    "    \n",
    "    USE_LEGACY = use_legacy\n",
    "    if USE_LEGACY:\n",
    "        tf.config.run_functions_eagerly(True)\n",
    "        PATH_TO_LABELS = './tensorflow_models/research/object_detection/data/oid_v4_label_map.pbtxt'\n",
    "    else:\n",
    "        tf.config.run_functions_eagerly(False)\n",
    "        PATH_TO_LABELS = './tensorflow_models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "    CATEGORY_INDEX = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4142c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "def load_model(model_handle):\n",
    "    if USE_LEGACY:\n",
    "        hub_model = hub.load(model_handle).signatures['default']\n",
    "    else:\n",
    "        hub_model = hub.load(model_handle)\n",
    "    \n",
    "    print('Model loaded!')\n",
    "    \n",
    "    return hub_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ccc0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all valid image paths\n",
    "# use image_type = 'colorized_artistic' for brighter/more daring colors\n",
    "# use image_type = 'grayscale' for the original grayscale images\n",
    "def get_valid_image_paths(path='inputs/colorized_stable/'):\n",
    "    valid_paths = []\n",
    "    for image_path in os.listdir(path):\n",
    "        if (image_path.endswith('.jpg')):\n",
    "            # Collect image as valid path\n",
    "            valid_paths.append(image_path)\n",
    "    return valid_paths\n",
    "\n",
    "# Load given image into numpy array using matplotlib imload\n",
    "def load_valid_image(filename, path='inputs/colorized_stable/'):\n",
    "    img = mpimg.imread(path + filename, format='jpg')\n",
    "    # Reshape image array to fit specifications required by tensorflow model\n",
    "    (rows, columns, channels) = img.shape\n",
    "    image = {\n",
    "        'image': img.reshape((1, rows, columns, channels)),\n",
    "        'filename': filename,\n",
    "        'detection': {}\n",
    "    }\n",
    "    return image\n",
    "\n",
    "# The images are objects of the shape:\n",
    "# {\n",
    "#     'image': Actual Image Object,\n",
    "#     'filename': Name of the original image\n",
    "# }\n",
    "def load_images(path='inputs/colorized_stable/'):\n",
    "    valid_paths = get_valid_image_paths(path)\n",
    "    \n",
    "    # How many images were loaded so far\n",
    "    progress_load = widgets.IntProgress(min=0, max=len(valid_paths), description='Loaded: ') # instantiate the bar\n",
    "    load_label = widgets.Label(value='0 / ' + str(len(valid_paths)))\n",
    "    display(widgets.HBox([progress_load, load_label])) # display the bar\n",
    "    \n",
    "    images = []\n",
    "    for filename in valid_paths:\n",
    "        images.append(load_valid_image(filename, path))\n",
    "        \n",
    "        progress_load.value += 1\n",
    "        load_label.value = str(progress_load.value) + ' / ' + str(len(valid_paths))\n",
    "        \n",
    "    return images\n",
    "\n",
    "def load_image(filename, path='inputs/colorized_stable/'):\n",
    "    return load_valid_image(filename, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6bf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_image(image, model):\n",
    "    # Run object detection and save results\n",
    "    if USE_LEGACY:\n",
    "        converted = tf.image.convert_image_dtype(image['image'], tf.float32)\n",
    "    else:\n",
    "        converted = image['image']\n",
    "    detected = model(converted)\n",
    "\n",
    "    return {key:value.numpy() for key,value in detected.items()}\n",
    "\n",
    "# Run inference with selected model on given images\n",
    "# The array of images that was returned contains objects of the shape:\n",
    "# {\n",
    "#     'image': Actual Image Object,\n",
    "#     'filename': Name of the original image\n",
    "#     'detection': Detected objects on the image\n",
    "# }\n",
    "def run_inference(images, model):\n",
    "    # How many images were used for inference so far\n",
    "    progress_inference = widgets.IntProgress(min=0, max=len(images), description='Inferred: ')\n",
    "    inference_label = widgets.Label(value='0 / ' + str(len(images)))\n",
    "    display(widgets.HBox([progress_inference, inference_label]))\n",
    "    \n",
    "    for index, image in enumerate(images):\n",
    "        image[index]['detection'] = run_inference_for_image(image, model)\n",
    "\n",
    "        progress_inference.value += 1\n",
    "        inference_label.value = str(progress_inference.value) + ' / ' + str(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fbf58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a shortened version of the tensorflow library function to visualize detections on images\n",
    "# It has been shortened/adapted to support the use of variable font-sized based on the images dimensions\n",
    "STANDARD_COLORS = [\n",
    "    'AliceBlue', 'Chartreuse', 'Aqua', 'Aquamarine', 'Azure', 'Beige', 'Bisque',\n",
    "    'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue', 'AntiqueWhite',\n",
    "    'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson', 'Cyan',\n",
    "    'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n",
    "    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet',\n",
    "    'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n",
    "    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'Gold', 'GoldenRod',\n",
    "    'Salmon', 'Tan', 'HoneyDew', 'HotPink', 'IndianRed', 'Ivory', 'Khaki',\n",
    "    'Lavender', 'LavenderBlush', 'LawnGreen', 'LemonChiffon', 'LightBlue',\n",
    "    'LightCoral', 'LightCyan', 'LightGoldenRodYellow', 'LightGray', 'LightGrey',\n",
    "    'LightGreen', 'LightPink', 'LightSalmon', 'LightSeaGreen', 'LightSkyBlue',\n",
    "    'LightSlateGray', 'LightSlateGrey', 'LightSteelBlue', 'LightYellow', 'Lime',\n",
    "    'LimeGreen', 'Linen', 'Magenta', 'MediumAquaMarine', 'MediumOrchid',\n",
    "    'MediumPurple', 'MediumSeaGreen', 'MediumSlateBlue', 'MediumSpringGreen',\n",
    "    'MediumTurquoise', 'MediumVioletRed', 'MintCream', 'MistyRose', 'Moccasin',\n",
    "    'NavajoWhite', 'OldLace', 'Olive', 'OliveDrab', 'Orange', 'OrangeRed',\n",
    "    'Orchid', 'PaleGoldenRod', 'PaleGreen', 'PaleTurquoise', 'PaleVioletRed',\n",
    "    'PapayaWhip', 'PeachPuff', 'Peru', 'Pink', 'Plum', 'PowderBlue', 'Purple',\n",
    "    'Red', 'RosyBrown', 'RoyalBlue', 'SaddleBrown', 'Green', 'SandyBrown',\n",
    "    'SeaGreen', 'SeaShell', 'Sienna', 'Silver', 'SkyBlue', 'SlateBlue',\n",
    "    'SlateGray', 'SlateGrey', 'Snow', 'SpringGreen', 'SteelBlue', 'GreenYellow',\n",
    "    'Teal', 'Thistle', 'Tomato', 'Turquoise', 'Violet', 'Wheat', 'White',\n",
    "    'WhiteSmoke', 'Yellow', 'YellowGreen'\n",
    "]\n",
    "\n",
    "def visualize_boxes_and_labels_on_image_array(\n",
    "    image,\n",
    "    boxes,\n",
    "    classes,\n",
    "    scores,\n",
    "    category_index,\n",
    "    use_normalized_coordinates=False,\n",
    "    max_boxes_to_draw=20,\n",
    "    min_score_thresh=.5,\n",
    "    agnostic_mode=False,\n",
    "    line_thickness=4,\n",
    "    font_size=24,\n",
    "    mask_alpha=.4,\n",
    "    groundtruth_box_visualization_color='black'):\n",
    "\n",
    "  # Create a display string (and color) for every box location, group any boxes\n",
    "  # that correspond to the same location.\n",
    "  box_to_display_str_map = collections.defaultdict(list)\n",
    "  box_to_color_map = collections.defaultdict(str)\n",
    "  box_to_track_ids_map = {}\n",
    "  if not max_boxes_to_draw:\n",
    "    max_boxes_to_draw = boxes.shape[0]\n",
    "  for i in range(boxes.shape[0]):\n",
    "    if max_boxes_to_draw == len(box_to_color_map):\n",
    "      break\n",
    "    if scores is None or scores[i] > min_score_thresh:\n",
    "      box = tuple(boxes[i].tolist())\n",
    "      if scores is None:\n",
    "        box_to_color_map[box] = groundtruth_box_visualization_color\n",
    "      else:\n",
    "        display_str = ''\n",
    "        if not agnostic_mode:\n",
    "            if classes[i] in six.viewkeys(category_index):\n",
    "              class_name = category_index[classes[i]]['name']\n",
    "            else:\n",
    "              class_name = 'N/A'\n",
    "            display_str = str(class_name) + ' '\n",
    "        box_to_display_str_map[box].append(display_str)\n",
    "        if agnostic_mode:\n",
    "          box_to_color_map[box] = 'DarkOrange'\n",
    "        else:\n",
    "          box_to_color_map[box] = STANDARD_COLORS[\n",
    "              classes[i] % len(STANDARD_COLORS)]\n",
    "\n",
    "  # Draw all boxes onto image.\n",
    "  for box, color in box_to_color_map.items():\n",
    "    ymin, xmin, ymax, xmax = box\n",
    "    draw_bounding_box_on_image_array(\n",
    "        image,\n",
    "        ymin,\n",
    "        xmin,\n",
    "        ymax,\n",
    "        xmax,\n",
    "        color=color,\n",
    "        thickness=line_thickness,\n",
    "        font_size=font_size,\n",
    "        display_str_list=box_to_display_str_map[box],\n",
    "        use_normalized_coordinates=use_normalized_coordinates)\n",
    "\n",
    "  return image\n",
    "\n",
    "def draw_bounding_box_on_image_array(\n",
    "    image,\n",
    "    ymin,\n",
    "    xmin,\n",
    "    ymax,\n",
    "    xmax,\n",
    "    color='red',\n",
    "    thickness=4,\n",
    "    font_size=24,\n",
    "    display_str_list=(),\n",
    "    use_normalized_coordinates=True):\n",
    "\n",
    "  image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "  draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color,\n",
    "                             thickness, font_size, display_str_list,\n",
    "                             use_normalized_coordinates)\n",
    "  np.copyto(image, np.array(image_pil))\n",
    "\n",
    "def draw_bounding_box_on_image(\n",
    "    image,\n",
    "    ymin,\n",
    "    xmin,\n",
    "    ymax,\n",
    "    xmax,\n",
    "    color='red',\n",
    "    thickness=4,\n",
    "    font_size=24,\n",
    "    display_str_list=(),\n",
    "    use_normalized_coordinates=True):\n",
    "\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  if use_normalized_coordinates:\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "  else:\n",
    "    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n",
    "  if thickness > 0:\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "               (left, top)],\n",
    "              width=thickness,\n",
    "              fill=color)\n",
    "  try:\n",
    "    font = ImageFont.truetype('arial.ttf', font_size)\n",
    "  except IOError:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "  # If the total height of the display strings added to the top of the bounding\n",
    "  # box exceeds the top of the image, stack the strings below the bounding box\n",
    "  # instead of above.\n",
    "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "  # Each display_str has a top and bottom margin of 0.05x.\n",
    "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "  if top > total_display_str_height:\n",
    "    text_bottom = top\n",
    "  else:\n",
    "    text_bottom = bottom + total_display_str_height\n",
    "  # Reverse list and print from bottom to top.\n",
    "  for display_str in display_str_list[::-1]:\n",
    "    text_width, text_height = font.getsize(display_str)\n",
    "    margin = np.ceil(0.05 * text_height)\n",
    "    draw.rectangle(\n",
    "        [(left, text_bottom - text_height - 2 * margin), (left + text_width,\n",
    "                                                          text_bottom)],\n",
    "        fill=color)\n",
    "    draw.text(\n",
    "        (left + margin, text_bottom - text_height - margin),\n",
    "        display_str,\n",
    "        fill='black',\n",
    "        font=font)\n",
    "    text_bottom -= text_height - 2 * margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336c8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine how many objects were inferred and which object types\n",
    "# The object that is returned will be of the following shape:\n",
    "# {\n",
    "#     'FILENAME': {\n",
    "#         'class': {\n",
    "#             'amount': int,\n",
    "#             'scores': [float],\n",
    "#             'boundingBoxes': [[ymin, xmin, ymax, xmax]]\n",
    "#         },\n",
    "#         'otherclass': {...},\n",
    "#         ...\n",
    "#     }\n",
    "# }\n",
    "def get_detections_for_image(image):\n",
    "    detections = image['detection']\n",
    "    boxes = detections['detection_boxes'] if USE_LEGACY else detections['detection_boxes'][0]\n",
    "    scores = detections['detection_scores'] if USE_LEGACY else detections['detection_scores'][0]\n",
    "    coordinates = {}\n",
    "    for i in range(boxes.shape[0]):\n",
    "        if scores[i] > THRESHOLD:\n",
    "            class_id = int(detections['detection_class_labels'][i]) if USE_LEGACY else int(detections['detection_classes'][0][i])\n",
    "\n",
    "            class_name = CATEGORY_INDEX[class_id]['name']\n",
    "\n",
    "            if class_name in coordinates:\n",
    "                coordinates[class_name]['amount'] += 1\n",
    "                coordinates[class_name]['scores'].append(scores[i])\n",
    "                coordinates[class_name]['boxes'].append(boxes[i])\n",
    "            else:\n",
    "                coordinates[class_name] = {\n",
    "                    'amount': 1,\n",
    "                    'scores': [scores[i]],\n",
    "                    'boxes': [boxes[i]]\n",
    "                }\n",
    "    return {\n",
    "        image['filename']: coordinates\n",
    "    }\n",
    "\n",
    "#\n",
    "# {\n",
    "#     'IMAGE1_FILENAME': {\n",
    "#         'class': {\n",
    "#             'amount': int,\n",
    "#             'scores': [float],\n",
    "#             'boundingBoxes': [[ymin, xmin, ymax, xmax]]\n",
    "#         },\n",
    "#         'otherclass': {...},\n",
    "#         ...\n",
    "#     },\n",
    "#     'IMAGE2_FILENAME': ...\n",
    "# }\n",
    "def get_detections_for_images(images):\n",
    "    all_detections = {}\n",
    "    \n",
    "    for image in images:\n",
    "        all_detections.update(get_detections_for_image(image))\n",
    "        \n",
    "    return all_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a5210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def font_size_for_width(width):\n",
    "    return int((width * 2) / 100)\n",
    "\n",
    "def line_width_for_width(width):\n",
    "    return int(np.log((width * 2) / 1000) * 5) + 1\n",
    "\n",
    "def draw_detections_on_image(image):\n",
    "    # Determine font size based on image width\n",
    "    (width, height, channels) = image['image'][0].shape\n",
    "\n",
    "    # Draw detections\n",
    "    visualize_boxes_and_labels_on_image_array(\n",
    "          image['image'][0],\n",
    "          image['detection']['detection_boxes'] if USE_LEGACY else image['detection']['detection_boxes'][0],\n",
    "          image['detection']['detection_class_labels'].astype(int) if USE_LEGACY else image['detection']['detection_classes'][0].astype(int),\n",
    "          image['detection']['detection_scores'] if USE_LEGACY else image['detection']['detection_scores'][0],\n",
    "          CATEGORY_INDEX,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          # Change this if confidence score should be higher or lower\n",
    "          min_score_thresh=THRESHOLD,\n",
    "          line_thickness=line_width_for_width(width),\n",
    "          font_size=font_size_for_width(width),\n",
    "          agnostic_mode=False\n",
    "    )\n",
    "\n",
    "# Draw detections on copied image\n",
    "def draw_detections_on_images(images_with_detections):\n",
    "    # How many detections were visualized so far\n",
    "    progress_save = widgets.IntProgress(min=0, max=len(images_with_detections), description='Visualized: ')\n",
    "    save_label = widgets.Label(value='0 / ' + str(len(images_with_detections)))\n",
    "    display(widgets.HBox([progress_save, save_label]))\n",
    "    \n",
    "    for image in images_with_detections:\n",
    "        draw_detections_on_image(image)\n",
    "\n",
    "        progress_save.value += 1\n",
    "        save_label.value = str(progress_save.value) + ' / ' + str(len(images_with_detections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677265ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(output_dir, image, filetype='jpg'):\n",
    "    # Create directory if not exists\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    plt.imsave(output_dir + image['filename'], image['image'][0], format=filetype)\n",
    "\n",
    "# Add output sub-directory named after the model that was used (if it doesn't already exist)\n",
    "def save_images(images_with_detections, model_name):\n",
    "    # How many images were saved so far\n",
    "    progress_save = widgets.IntProgress(min=0, max=len(images_with_detections), description='Saved: ')\n",
    "    save_label = widgets.Label(value='0 / ' + str(len(images_with_detections)))\n",
    "    display(widgets.HBox([progress_save, save_label]))\n",
    "    \n",
    "    output_dir = 'outputs/' + model_name + '/'\n",
    "\n",
    "    # Save images\n",
    "    for image in images_with_detections:\n",
    "        save_image(output_dir + image['filename'], image)\n",
    "        \n",
    "        progress_save.value += 1\n",
    "        save_label.value = str(progress_save.value) + ' / ' + str(len(images_with_detections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6a460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you want statistics on all inferences run for each model\n",
    "# @param image_count: number of images that were used \n",
    "def get_statistics_for_detections(detections, image_count, single=False):\n",
    "    dataFrame = pd.DataFrame([detections], index=range(1, image_count + 1))\n",
    "    \n",
    "    if single:\n",
    "        dataFrame[dataFrame.columns[0]].name = MODEL_NAME\n",
    "\n",
    "    pathlib.Path('outputs/statistics/').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if single:\n",
    "        dataFrame.to_csv('outputs/statistics/detections_single.csv')\n",
    "    else:\n",
    "        dataFrame.to_csv('outputs/statistics/detections_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "137924d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(name):\n",
    "    plt.savefig(name + '.svg', format='svg', bbox_inches='tight')\n",
    "    plt.savefig(name + '.jpg', format='jpg', bbox_inches='tight')\n",
    "    plt.savefig(name + '.pgf', format='pgf', bbox_inches='tight')\n",
    "\n",
    "# Run this for charts\n",
    "# @param image_count: number of images that were used\n",
    "def generate_detection_charts(all_detections, image_count):\n",
    "    plt.figure()\n",
    "    \n",
    "    # Total detections per image\n",
    "    total_detections = {}\n",
    "    for model, detections in all_detections.items():\n",
    "        model_detections = [np.sum([info['amount'] for label, info in stats.items()]) for filename, stats in detections.items()]\n",
    "        total_detections[model] = np.sum(model_detections)\n",
    "        print(model + ':', total_detections[model])\n",
    "        plt.plot(model_detections)\n",
    "    plt.legend(list(total_detections.keys()), loc='upper left')\n",
    "    \n",
    "    save_fig('outputs/statistics/statistics_by_image')\n",
    "    \n",
    "    # Average detections per image\n",
    "    plt.figure()\n",
    "    plt.barh(\n",
    "        [name for name in total_detections.keys()],\n",
    "        [value / image_count for value in total_detections.values()]\n",
    "    )\n",
    "\n",
    "    save_fig('outputs/statistics/statistics_average')\n",
    "\n",
    "# Run this for charts for a single model\n",
    "# @param image_count: number of images that were used\n",
    "def generate_detection_chart(detections, image_count):\n",
    "    plt.figure()\n",
    "    \n",
    "    # Total detections per image\n",
    "    model_detections = [np.sum([info['amount'] for label, info in stats.items()]) for filename, stats in DETECTED_CLASSES.items()]\n",
    "    plt.plot(model_detections)\n",
    "    \n",
    "    total_detections = np.sum(model_detections)\n",
    "    print('Average detections per image: %.2f' % (total_detections / image_count))\n",
    "    \n",
    "    plt.ylabel('Detections per Image')\n",
    "    plt.xlabel('Image Index')\n",
    "    plt.legend([MODEL_NAME], loc='upper right')\n",
    "\n",
    "    plt.savefig('outputs/statistics/statistics_single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701652f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\n",
    "    'lang': 'EN',\n",
    "    'word': ''\n",
    "}\n",
    "synset_params = {\n",
    "    'searchLang': 'EN',\n",
    "    'targetLang': 'EN',\n",
    "    'key': 'efeb755b-7c79-41f9-abd3-22d25254c9c2',\n",
    "    'id': ''\n",
    "}\n",
    "\n",
    "# Get all detected labels, without duplicates\n",
    "# The returned array will contain objects of the following structure:\n",
    "#{\n",
    "#    'class': string,\n",
    "#    'babelnetid': string,\n",
    "#    'wikidataid': string,\n",
    "#    'babelnet': url,\n",
    "#    'wikidata': url,\n",
    "#    'labelMatch': boolean  # True if label of mapped Wikidata Entity exactly matches the class name\n",
    "#}\n",
    "def get_detected_labels(detections):\n",
    "    labels = [label for stats in detections.values() for label in stats]\n",
    "    return list(map(lambda x: {'class': x.capitalize(), 'babelnetid': '', 'wikidataid': '', 'babelnet': '', 'wikidata': '', 'labelMatch': False}, list(dict.fromkeys(labels))))\n",
    "\n",
    "def make_http_request(url, params, encoding):\n",
    "    babelnet_request = request.Request(url + '?' + parse.urlencode(params))\n",
    "    if encoding != 'html':\n",
    "        babelnet_request.add_header('Accept-encoding', encoding)\n",
    "    response = request.urlopen(babelnet_request)\n",
    "    \n",
    "    if encoding != 'html' and response.info().get('Content-Encoding') == encoding:\n",
    "        buf = BytesIO(response.read())\n",
    "        f = gzip.GzipFile(fileobj=buf)\n",
    "        return json.loads(f.read())\n",
    "    else:\n",
    "        return response.read().decode('utf8')\n",
    "\n",
    "    \n",
    "def get_search_page_for(label):\n",
    "    search_params['word'] = label\n",
    "    html = make_http_request('https://babelnet.org/search', search_params, 'html')\n",
    "    search_params['word'] = ''\n",
    "    return html\n",
    "\n",
    "# Get synset for a given sense\n",
    "def get_synset_for(synset_id):\n",
    "    synset_params['id'] = synset_id\n",
    "    synset = make_http_request('https://babelnet.io/v6/getSynset', synset_params, 'gzip')\n",
    "    synset_params['id'] = ''\n",
    "    return synset\n",
    "        \n",
    "# Optimize relation checking, sometimes entries have multiple wikidata sources which are sorted\n",
    "# alphabetically (not by importance), therefore a different wikidata source could be a more\n",
    "# accurate representation\n",
    "def find_exact_match(senses, label):\n",
    "    sense = None\n",
    "    \n",
    "    # Search for exact match\n",
    "    for current in senses:\n",
    "        # Remove all non-alphabetic characters\n",
    "        lemma = re.sub('[^a-zA-Z]', '', current['properties']['fullLemma'])\n",
    "        label = re.sub('[^a-zA-Z]', '', label)\n",
    "\n",
    "        # Compare lowercase representations of label and lemma\n",
    "        if label.casefold() in lemma.casefold():\n",
    "            sense = current\n",
    "            break\n",
    "                \n",
    "    return sense\n",
    "\n",
    "# Read information from sense into given label\n",
    "def update_label_from_sense(label, sense):\n",
    "    if sense is not None:\n",
    "        label['babelnetid'] = sense['properties']['synsetID']['id']\n",
    "        label['babelnet'] = 'http://babelnet.org/synset?lang=EN&id=' + sense['properties']['synsetID']['id'].replace(':', '%3A')\n",
    "        label['wikidataid'] = sense['properties']['senseKey']\n",
    "        label['wikidata'] = 'http://www.wikidata.org/wiki/' + sense['properties']['senseKey']\n",
    "        \n",
    "        lemma = re.sub('[^a-zA-Z]', '', sense['properties']['fullLemma'])\n",
    "        class_label = re.sub('[^a-zA-Z]', '', label['class'])\n",
    "        label['labelMatch'] = class_label.casefold() == lemma.casefold()\n",
    "    else:\n",
    "        label['babelnetid'] = 'No match'\n",
    "        label['babelnet'] = 'No match'\n",
    "        label['wikidataid'] = 'No match'\n",
    "        label['wikidata'] = 'No match'\n",
    "        label['labelMatch'] = False\n",
    "\n",
    "# Use page crawler to get BableNet senses for detections, based on ranking on the BableNet search page\n",
    "def get_entity_mapping(detection_labels):\n",
    "    for label in detection_labels:\n",
    "        print('Label:', label['class'])\n",
    "        soup = BeautifulSoup(get_search_page_for(label['class']), 'html.parser')\n",
    "        synsets_html = soup.select('div[data-type=\"CONCEPT\"]')\n",
    "        synset_detail_html = soup.select_one('.synset-wrapper')\n",
    "        \n",
    "        first = None\n",
    "        sense = None\n",
    "        # Search page\n",
    "        if len(synsets_html) > 0:\n",
    "            # Limit amount of searched synsets to a maximum of 3\n",
    "            for synset_html in synsets_html[:min(4, len(synsets_html))]:\n",
    "                try:\n",
    "                    synset = get_synset_for(synset_html['data-id'])\n",
    "                    senses = [sense for sense in synset['senses'] if sense['properties']['source'] == 'WIKIDATA']\n",
    "                    \n",
    "                    # Remember first set of senses and use first of these senses as fallback if no exact match can\n",
    "                    # be found\n",
    "                    if first is None and len(senses) > 0:\n",
    "                        first = senses[0]\n",
    "\n",
    "                    sense = find_exact_match(senses, label['class'])\n",
    "                    \n",
    "                    # We have found an exact match and do not have to look further\n",
    "                    if sense is not None:\n",
    "                        break\n",
    "                except:\n",
    "                    print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "                    print(synset_html)\n",
    "        # Detail page\n",
    "        elif synset_detail_html is not None:\n",
    "            synset_id = soup.select_one('.id')\n",
    "            try:\n",
    "                synset = get_synset_for(synset_id.text)\n",
    "                senses = [sense for sense in synset['senses'] if sense['properties']['source'] == 'WIKIDATA']\n",
    "                \n",
    "                if len(senses) > 0:\n",
    "                    first = senses[0]\n",
    "                sense = find_exact_match(senses, label['class'])\n",
    "            except:\n",
    "                print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "                print(synset_html)\n",
    "        \n",
    "        # If no exact match could be found, just use the first sense of the first result\n",
    "        if sense is None and first is not None:\n",
    "            sense = first\n",
    "        \n",
    "        update_label_from_sense(label, sense)\n",
    "        \n",
    "def save_entity_mapping(mapped_entities, path):\n",
    "    pd.DataFrame(mapped_entities).to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8193a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_participant_statistics(series, separated, name):\n",
    "    data = series\n",
    "    if not separated:\n",
    "        data = [series]\n",
    "    plot = pd.DataFrame(data).plot(\n",
    "        kind='barh',\n",
    "        legend=False\n",
    "    )\n",
    "    if not separated:\n",
    "        plot.legend(prop={'size': 14})\n",
    "        plot.tick_params(bottom=False, labelbottom=False)\n",
    "        \n",
    "    save_fig('outputs/statistics/survey_' + name)\n",
    "    \n",
    "# Generate statistics about study participants\n",
    "def generate_participant_statistics(results, separated=True):\n",
    "    # How many participants have completed the survey\n",
    "    labels = ['None', '1-5\\n(Background)', '6-100', '101-200', '201-324', '325\\n(Completed)']\n",
    "    if not separated:\n",
    "        labels = ['None', '1-5 (Background)', '6-100', '101-200', '201-324', '325 (Completed)']\n",
    "    lastpage = pd.cut(\n",
    "        results[results.columns[0]].fillna(0),\n",
    "        bins=[0, 1, 5, 100, 200, 324, 327],\n",
    "        # Combined bars\n",
    "        # labels=['None', '1-5 (Background)', '6-100', '101-200', '201-324', '325 (Completed)'],\n",
    "        # Separate bars\n",
    "        labels=labels,\n",
    "        include_lowest=True\n",
    "    ).value_counts(dropna=False).sort_index()\n",
    "    lastpage.name = 'Completion'\n",
    "    plot_participant_statistics(lastpage, separated, 'questions')\n",
    "    \n",
    "    # Gender\n",
    "    gender = results[results.columns[1]].value_counts().sort_index()\n",
    "    gender.name = 'Gender'\n",
    "    plot_participant_statistics(gender, separated, 'gender')\n",
    "    \n",
    "    # Field of employment\n",
    "    employment = {}\n",
    "    for column_name in results.iloc[:, 2:8]:\n",
    "        column = results[column_name].value_counts()\n",
    "        employment[column_name[column_name.find(\"[\")+1:column_name.find(\"]\")]] = column['Yes']\n",
    "    employment['Other'] = results.iloc[:, 8:9].value_counts().sum()\n",
    "    employment_series = pd.Series(employment)\n",
    "    employment_series.name = 'Field of employment'\n",
    "    plot_participant_statistics(employment_series, separated, 'employment')\n",
    "    \n",
    "    # Age\n",
    "    age = pd.cut(\n",
    "        results[results.columns[9]].dropna().apply(\n",
    "            lambda x: 0 if type(x) == str and x == 'Prefer not to answer' else int(x)\n",
    "        ),\n",
    "        bins=[0, 18, 24, 30, 40, 50, 1000],\n",
    "        labels=['Prefer not to answer', '18-24', '25-30', '31-40', '40-50', 'Over 50'],\n",
    "        include_lowest=True\n",
    "    ).value_counts().sort_index()\n",
    "    age.name = 'Age groups'\n",
    "    plot_participant_statistics(age, separated, 'age')\n",
    "    \n",
    "    # Educational background\n",
    "    education = results[results.columns[10]].value_counts()\n",
    "    education.name = 'Educational background'\n",
    "    plot_participant_statistics(education, separated, 'education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ce27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The subjects in our case are the survey questions and there are 320 of them\n",
    "# The categories in our case are the 5 options of the Likkert-Scale we chose\n",
    "# Therefore we want a matrix that looks like this:\n",
    "#\n",
    "# Header:       \"Very inaccurate\", \"Mostly inaccurate\", \"Neither\", \"Mostly accurate\", \"Very accurate\"\n",
    "# Question 1:  [       0                   1               0              1                 10       ]\n",
    "# Question 2:  [                                          ...                                        ]\n",
    "# ...\n",
    "#\n",
    "# M[0,0] = Number of participants (0), that assigned the first question to the first category (\"Very inaccurate\")\n",
    "def calculate_iaa(detection_results):\n",
    "    matrix = detection_results.dropna().to_numpy().T\n",
    "    iaa = []\n",
    "    \n",
    "    for row in matrix:\n",
    "        unique, counts = np.unique(row, return_counts=True)\n",
    "        \n",
    "        new_row = np.zeros(5)\n",
    "        for index, current in enumerate(unique):\n",
    "            if current == 'Very inaccurate':\n",
    "                new_row[0] = counts[index]\n",
    "            elif current == 'Mostly inaccurate':\n",
    "                new_row[1] = counts[index]\n",
    "            elif current == 'Neither accurate nor inaccurate':\n",
    "                new_row[2] = counts[index]\n",
    "            elif current == 'Mostly accurate':\n",
    "                new_row[3] = counts[index]\n",
    "            elif current == 'Very accurate':\n",
    "                new_row[4] = counts[index]\n",
    "\n",
    "        iaa.append(new_row)\n",
    "    \n",
    "    return fleiss_kappa(np.asmatrix(iaa))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
